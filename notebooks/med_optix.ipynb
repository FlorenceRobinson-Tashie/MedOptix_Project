{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a131d81",
   "metadata": {},
   "source": [
    "### A. Upload CSVs to S3 (using boto3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de90c7c",
   "metadata": {},
   "source": [
    "#### Import All Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2977cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import boto3\n",
    "import os\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b8ddde",
   "metadata": {},
   "outputs": [
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload ../medoptix_data/raw\\clinics.csv to flo-amdari-demo-etl//medoptix/raw/clinics.csv: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSuchBucket\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\boto3\\s3\\transfer.py:372\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\futures.py:287\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\tasks.py:142\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transfer_coordinator.done():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\tasks.py:165\u001b[39m, in \u001b[36mTask._execute_main\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\upload.py:796\u001b[39m, in \u001b[36mPutObjectTask._main\u001b[39m\u001b[34m(self, client, fileobj, bucket, key, extra_args)\u001b[39m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fileobj \u001b[38;5;28;01mas\u001b[39;00m body:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\client.py:601\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\client.py:1074\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1073\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNoSuchBucket\u001b[39m: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mS3UploadFailedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename.endswith(\u001b[33m\"\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     12\u001b[39m     filepath = os.path.join(folder_data, filename)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\boto3\\s3\\inject.py:175\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\boto3\\s3\\transfer.py:378\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m S3UploadFailedError(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to upload \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    380\u001b[39m             filename, \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m.join([bucket, key]), e\n\u001b[32m    381\u001b[39m         )\n\u001b[32m    382\u001b[39m     )\n",
      "\u001b[31mS3UploadFailedError\u001b[39m: Failed to upload ../medoptix_data/raw\\clinics.csv to flo-amdari-demo-etl//medoptix/raw/clinics.csv: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "bucket_name = \"flo-amdari-demo-etl\"\n",
    "folder_data = \"../medoptix_data/raw\"\n",
    "target_folder = \"/medoptix/raw/\"\n",
    "\n",
    "# AWS credentials assumed to be in ~/.aws/credentials or env vars\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Upload all CSVs in folder with ACL: bucket-owner-full-control \n",
    "for filename in os.listdir(folder_data):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(folder_data, filename)\n",
    "        s3.upload_file(\n",
    "            Filename = filepath,\n",
    "            Bucket = bucket_name,\n",
    "            Key = target_folder + filename\n",
    "        )\n",
    "        print(f\"uploaded {filename} successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ea67f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitkeep', 'clinics.csv', 'dropout_flags.csv', 'feedback.csv', 'interventions.csv', 'patients.csv', 'sessions.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../medoptix_data/raw\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitkeep', 'clinics.csv', 'dropout_flags.csv', 'feedback.csv', 'interventions.csv', 'patients.csv', 'sessions.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(folder_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39.3\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "print(boto3.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ac67c",
   "metadata": {},
   "source": [
    "### B. Load from S3 → PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe78344",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Download files\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⬇️ Downloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from S3\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\boto3\\s3\\inject.py:223\u001b[39m, in \u001b[36mdownload_file\u001b[39m\u001b[34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\boto3\\s3\\transfer.py:406\u001b[39m, in \u001b[36mS3Transfer.download_file\u001b[39m\u001b[34m(self, bucket, key, filename, extra_args, callback)\u001b[39m\n\u001b[32m    402\u001b[39m future = \u001b[38;5;28mself\u001b[39m._manager.download(\n\u001b[32m    403\u001b[39m     bucket, key, filename, extra_args, subscribers\n\u001b[32m    404\u001b[39m )\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\futures.py:287\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\tasks.py:272\u001b[39m, in \u001b[36mSubmissionTask._main\u001b[39m\u001b[34m(self, transfer_future, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m._transfer_coordinator.set_status_to_running()\n\u001b[32m    270\u001b[39m     \u001b[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# transfer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    274\u001b[39m     \u001b[38;5;66;03m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m \n\u001b[32m    285\u001b[39m     \u001b[38;5;66;03m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_and_set_exception(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\s3transfer\\download.py:355\u001b[39m, in \u001b[36mDownloadSubmissionTask._submit\u001b[39m\u001b[34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[32m    327\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m \u001b[33;03m    downloading streams\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    352\u001b[39m     transfer_future.meta.size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    353\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m transfer_future.meta.etag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;66;03m# user.\u001b[39;00m\n\u001b[32m    362\u001b[39m     transfer_future.meta.provide_transfer_size(\n\u001b[32m    363\u001b[39m         response[\u001b[33m'\u001b[39m\u001b[33mContentLength\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    364\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\client.py:601\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    598\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    599\u001b[39m     )\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Florence Personal\\Documents\\Data Science Projects\\Amdari Accelerate Internship Projects Folder\\MedOptix_Project_Folder\\med_env\\Lib\\site-packages\\botocore\\client.py:1074\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1070\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1071\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1072\u001b[39m     )\n\u001b[32m   1073\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1076\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mClientError\u001b[39m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "bucket = \"flo-amdari-demo-etl\"\n",
    "prefix = \"medoptix/raw/\"\n",
    "\n",
    "# Files to download\n",
    "files = [\"patients.csv\", \"clinics.csv\", \"sessions.csv\", \"feedback.csv\", \"dropout_flags.csv\"]\n",
    "\n",
    "# Download files\n",
    "for file in files:\n",
    "    s3.download_file(bucket, prefix + file, file)\n",
    "    print(f\"⬇️ Downloaded {file} from S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10b2ce",
   "metadata": {},
   "source": [
    "### Data Modelling & Defining Foreign Key relationships\n",
    "patients (PK: patient_id)\n",
    "sessions (PK: session_id, FK: patient_id)\n",
    "feedback (PK: feedback_id, FK: session_id)\n",
    "TASK 1 - Model and Define the relationship for the remaining set of dataset\n",
    "\n",
    "clinics\n",
    "dropout_flags\n",
    "intervention.csv\n",
    "TASK 2 - Create Schema for these dataset and upload them into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb511aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08278870",
   "metadata": {},
   "source": [
    "### C. Upload Data → PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee147c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (recommended for security)\n",
    "load_dotenv()\n",
    "\n",
    "def get_db_engine():\n",
    "    \"\"\"Create and return a SQLAlchemy engine with proper connection string\"\"\"\n",
    "    # Construct connection string from environment variables\n",
    "    db_url = (\n",
    "        f\"postgresql://{''}:{''}@\"\n",
    "        f\"{''}:{''}/{''}?\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "def upload_data():\n",
    "    # Step 1: Read CSV files\n",
    "    patients = pd.read_csv(\"C:/Users/Muham/Downloads/Medoptix_Demo/medoptix_data/processed/patients.csv\")\n",
    "    sessions = pd.read_csv(\"C:/Users/Muham/Downloads/Medoptix_Demo/medoptix_data/processed/sessions.csv\")\n",
    "    feedback = pd.read_csv(\"C:/Users/Muham/Downloads/Medoptix_Demo/medoptix_data/processed/feedback.csv\")\n",
    "\n",
    "    # Step 2: Create database engine\n",
    "    engine = get_db_engine()\n",
    "\n",
    "    # Step 3: Upload in referential order with error handling\n",
    "    with engine.begin() as connection:  # Automatically handles transactions\n",
    "        # Chunk size for large datasets (adjust as needed)\n",
    "        chunk_size = 1000\n",
    "\n",
    "        # Upload patients table\n",
    "        patients.to_sql(\n",
    "            \"patients\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'  # Faster for bulk inserts\n",
    "        )\n",
    "\n",
    "        # Upload sessions table\n",
    "        sessions.to_sql(\n",
    "            \"sessions\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'\n",
    "        )\n",
    "\n",
    "        # Upload feedback table\n",
    "        feedback.to_sql(\n",
    "            \"feedback\", \n",
    "            connection, \n",
    "            if_exists=\"append\", \n",
    "            index=False,\n",
    "            chunksize=chunk_size,\n",
    "            method='multi'\n",
    "        )\n",
    "\n",
    "    print(\"✅ Data uploaded successfully with relationships intact.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    upload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e683c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f1b548",
   "metadata": {},
   "source": [
    "### D. Read Data → PostgreSQL - (Prepare data for EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7925a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_db_engine():\n",
    "    \"\"\"Create and return a SQLAlchemy engine with proper connection string\"\"\"\n",
    "    # Construct connection string from environment variables\n",
    "    db_url = (\n",
    "        f\"postgresql://{''}:{''}@\"\n",
    "        f\"{''}:{''}/{''}?\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "\n",
    "engine = get_db_engine()\n",
    "\n",
    "\n",
    "# Query to fetch data from the tables\n",
    "patients_query = \"SELECT * FROM patients\"\n",
    "sessions_query = \"SELECT * FROM sessions\"\n",
    "feedback_query = \"SELECT * FROM feedback\"\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "patients_df = pd.read_sql(patients_query, engine)\n",
    "sessions_df = pd.read_sql(sessions_query, engine)\n",
    "feedback_df = pd.read_sql(feedback_query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42efa4",
   "metadata": {},
   "source": [
    "### D1- Display basic info and summary statistics for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e174361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients\n",
    "print(\"Patients Data Overview\")\n",
    "patients_df.head(2)\n",
    "patients_df.info()\n",
    "patients_df.describe()\n",
    "\n",
    "# Sessions\n",
    "print(\"Sessions Data Overview\")\n",
    "sessions_df.head(2)\n",
    "sessions_df.info()\n",
    "sessions_df.describe()\n",
    "\n",
    "\n",
    "# Feedback\n",
    "print(\"Feedback Data Overview\")\n",
    "feedback_df.head()\n",
    "feedback_df.info()\n",
    "feedback_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50c44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a649167",
   "metadata": {},
   "source": [
    "### E. EDA → (Exploratory Data Analysis)\n",
    "\n",
    "Steps in EDA\n",
    "\n",
    "Data Exploration\n",
    "Head()\n",
    "info()\n",
    "describe()\n",
    "Data Cleaning\n",
    "Identifying & Handling Missing Values\n",
    "Identifying & Handling Duplicates\n",
    "Data Transformation (Feature Engineering)\n",
    "Standardizing data types (text, date, replacing values)\n",
    "Log Transform (for highly skewed data e.g., income, prices)\n",
    "Binning (Convert continuous variables into categorical bins e.g., age ranges)\n",
    "Encoding (Convert categorical variables into numerical format (e.g., One-Hot, Label Encoding))\n",
    "Data Distributions\n",
    "Histograms for distributions of numerical features (age, bmi etc)- Also to check if the features are normally distributed or skewed (e.g., pain level or age should be somewhat evenly distributed just like we discovered in the last drop-in session).\n",
    "Boxplots to detect outliers & handle them.\n",
    "Pairplots to visualize relationships between multiple features.\n",
    "Correlation Analysis (dentify relationships between variables that may help in predictive modeling)\n",
    "Correlation Matrix to understand feature dependencies.\n",
    "Heatmap for visual representation of correlations.\n",
    "Understanding Dropout Behavior\n",
    "investigate the correlation between features and patient dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962090a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42b6bd87",
   "metadata": {},
   "source": [
    "### E-2: Data Cleaning (Handling Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Check for Missing Values in All Tables\n",
    "print(\"\\nMissing Values in Patients Data:\")\n",
    "print(patients_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Sessions Data:\")\n",
    "print(sessions_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Feedback Data:\")\n",
    "print(feedback_df.isnull().sum())\n",
    "\n",
    "# 6. Clean Missing Values\n",
    "# Example of filling missing values for categorical and numerical data\n",
    "patients_df['chronic_cond'] = patients_df['chronic_cond'].fillna(patients_df['chronic_cond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if null values has been properly handled\n",
    "patients_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2a9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab644f6d",
   "metadata": {},
   "source": [
    "### E-3 - TASK 3 (Data Cleaning)\n",
    "Identifying & Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d7cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf6ac4a1",
   "metadata": {},
   "source": [
    "## F. Data transformation (Feature Engineering)\n",
    "F-1 Standardizing data types (Signup_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c306c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df['signup_date'] = pd.to_datetime(patients_df['signup_date'])\n",
    "sessions_df['date'] = pd.to_datetime(sessions_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e2acd",
   "metadata": {},
   "source": [
    "#### F-2 Binning (putting the age into categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Add age group column for segmentation\n",
    "bins = [0, 18, 35, 55, np.inf]\n",
    "labels = ['0-18', '19-35', '36-55', '55+']\n",
    "patients_df['age_group'] = pd.cut(patients_df['age'], bins=bins, labels=labels)\n",
    "patients_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc131108",
   "metadata": {},
   "source": [
    "F-3 : TASK 4 (Data Transformation)\n",
    "\n",
    "Log Transform (for highly skewed data e.g., income, prices)\n",
    "Encoding (Convert categorical variables into numerical format (e.g., One-Hot, Label Encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189f316",
   "metadata": {},
   "source": [
    "### G. Data Distribution\n",
    "#### G-1 Histograms for distributions of numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee906d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram for distribution of pain level\n",
    "sns.histplot(sessions_df['pain_level'], kde=True)\n",
    "plt.title('Distribution of Pain Level')\n",
    "plt.show()\n",
    "\n",
    "# Age distribution for patients (histogram)\n",
    "sns.histplot(patients_df['age'], kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a308",
   "metadata": {},
   "source": [
    "### G-2 TASK 5 (Data Distribution)\n",
    "Boxplots to detect outliers & handle them.\n",
    "Pairplots to visualize relationships between multiple features.\n",
    "H. CORRELATION ANALYSIS\n",
    "H-1 TASK 6 (Correlation Analysis)\n",
    "Correlation Analysis (dentify relationships between variables that may help in predictive modeling)\n",
    "Correlation Matrix to understand feature dependencies.\n",
    "Heatmap for visual representation of correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc319a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93b1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c3baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
